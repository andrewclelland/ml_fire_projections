{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12751844-e81c-466b-b55f-d8915a6cc3fc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04aa33e9-3d65-4795-ac3f-f593400d94a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import calendar\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccb3106-6415-458f-a7f1-569d8148ffb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "ee.Authenticate()\n",
    "ee.Initialize(project='spherical-berm-323321') # <-- Edit project as necessary\n",
    "\n",
    "# Consistent Parameters\n",
    "final = ee.FeatureCollection('users/andyc97/model_preprocessed/final_shapefile') # GEE asset location of shapefile which you want to iterate over\n",
    "quarter_degree_grid = ee.FeatureCollection('users/andyc97/model_preprocessed/quarter_degree_grid') # GEE asset location where you want to save grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7737702d-2d5e-4dcb-b777-57ff51380cae",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Make grid to iterate over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc607b1-2bd0-4abe-a3f0-28d1e880cd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your FeatureCollection\n",
    "boreal_tundra_region = final\n",
    "\n",
    "# Define the spatial resolution and grid size in pixels.\n",
    "resolution = 27830\n",
    "grid_size_pixels = 64\n",
    "grid_size_meters = resolution * grid_size_pixels\n",
    "\n",
    "# Get the bounding box of the region\n",
    "region_bounds = boreal_tundra_region.geometry().bounds()\n",
    "\n",
    "# Get the coordinates of the bounding box\n",
    "region_coords = region_bounds.coordinates().get(0).getInfo()\n",
    "\n",
    "# Define the coordinates of the bounding box\n",
    "min_lon = region_coords[0][0]\n",
    "min_lat = region_coords[0][1]\n",
    "max_lon = region_coords[2][0]\n",
    "max_lat = region_coords[2][1]\n",
    "\n",
    "# Create a list to hold the grid cells\n",
    "grid_cells = []\n",
    "\n",
    "# Generate the grid cells\n",
    "lon = min_lon\n",
    "while lon < max_lon:\n",
    "    lat = min_lat\n",
    "    while lat < max_lat:\n",
    "        cell = ee.Geometry.Rectangle([lon, lat, lon + (grid_size_meters / 111320), lat + (grid_size_meters / 111320)])\n",
    "        grid_cells.append(ee.Feature(cell))\n",
    "        lat += (grid_size_meters / 111320)\n",
    "    lon += (grid_size_meters / 111320)\n",
    "\n",
    "# Create a FeatureCollection from the grid cells\n",
    "grid_feature_collection = ee.FeatureCollection(grid_cells)\n",
    "\n",
    "# Filter the grid cells to retain only those within the region\n",
    "filtered_grid_cells = grid_feature_collection.filterBounds(boreal_tundra_region.geometry())\n",
    "final_grid = ee.FeatureCollection(filtered_grid_cells)\n",
    "\n",
    "# Print the number of grid cells created\n",
    "print(f\"Number of grid cells created: {final_grid.size().getInfo()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fa694c-cb49-4130-9feb-006507a2c846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export grid to asset\n",
    "task = ee.batch.Export.table.toAsset(\n",
    "    collection=ee.FeatureCollection(final_grid),\n",
    "    description='test_grid',\n",
    "    assetId='users/andyc97/model_preprocessed/quarter_degree_grid') # <-- Edit save location\n",
    "task.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddecd81-e227-4700-8920-5f54245dda97",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Process CEMS to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092177a2-d2c4-439b-a7b7-2e5b45d13fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import downscaled FWI into an image collection\n",
    "# Run and save single years before combining into one master file\n",
    "years = list(range(2014, 2015))  # 2001 to 2014\n",
    "months = list(range(1, 13))  # 1 to 12\n",
    "\n",
    "# Google Cloud Storage bucket path template to CEMS - DO NOT CHANGE!\n",
    "gcs_template = 'gs://ce-cems-fire-daily-4-1/{year}{month}{day}.tif'\n",
    "\n",
    "# Function to generate monthly mean image for a given year and month\n",
    "def create_monthly_mean_image(year, month):\n",
    "    # Get the number of days in the month\n",
    "    _, last_day = calendar.monthrange(year, month)\n",
    "    \n",
    "    # Initialize an empty ImageCollection for the month\n",
    "    monthly_images = ee.ImageCollection([])\n",
    "\n",
    "    # Loop through each day of the month\n",
    "    for day in range(1, last_day + 1):\n",
    "        # Format the file path\n",
    "        file_path = gcs_template.format(year=year, month=f'{month:02d}', day=f'{day:02d}')\n",
    "        \n",
    "        try:\n",
    "            # Load the GeoTIFF image from GCS\n",
    "            daily_image = ee.Image.loadGeoTIFF(file_path).clip(final)\n",
    "                  \n",
    "            # Handle missing pixels for BUI and FWI bands\n",
    "            bui_filled = daily_image.select('build_up_index').unmask(-9999, sameFootprint=True).updateMask(daily_image.select('fine_fuel_moisture_code'))\n",
    "            fwi_filled = daily_image.select('fire_weather_index').unmask(-9999, sameFootprint=True).updateMask(daily_image.select('fine_fuel_moisture_code'))\n",
    "            \n",
    "            # Replace the original BUI and FWI with the filled versions\n",
    "            daily_image = daily_image.addBands([bui_filled.rename('build_up_index'), fwi_filled.rename('fire_weather_index')], overwrite=True)\n",
    "            \n",
    "            # Add the daily image to the collection\n",
    "            monthly_images = monthly_images.merge(ee.ImageCollection([daily_image]))\n",
    "        \n",
    "        except Exception as e:\n",
    "            # Handle missing files or errors in loading\n",
    "            print(f'Failed to load {file_path}: {e}')\n",
    "            continue\n",
    "\n",
    "    # Calculate the mean of the monthly images\n",
    "    monthly_mean_image = monthly_images.mean()\n",
    "    \n",
    "    # Get coordinates and add to the image\n",
    "    coords = ee.Image.pixelLonLat().clip(final).updateMask(monthly_mean_image.select('fine_fuel_moisture_code'))\n",
    "    monthly_mean_image = monthly_mean_image.addBands(coords)\n",
    "\n",
    "    # Set properties including the start and end dates\n",
    "    start_date = f'{year}-{month:02d}-01'\n",
    "    end_date = f'{year}-{month:02d}-{last_day:02d}'\n",
    "    \n",
    "    monthly_mean_image = monthly_mean_image.set({\n",
    "        'scenario': 'historical',\n",
    "        'year': year,\n",
    "        'month': month,\n",
    "        'system:time_start': ee.Date(start_date).millis(),\n",
    "        'system:time_end': ee.Date(end_date).millis()\n",
    "    })\n",
    "\n",
    "    return monthly_mean_image\n",
    "\n",
    "# Create an empty list to hold the images\n",
    "image_list = []\n",
    "\n",
    "# Loop through scenarios, years, and months, and import the files\n",
    "for year in years:\n",
    "    for month in months:\n",
    "        try:\n",
    "            image = create_monthly_mean_image(year, month)\n",
    "            image_list.append(image)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image for {year}-{month}: {e}\")\n",
    "\n",
    "# Convert the list of images to an Earth Engine ImageCollection\n",
    "monthly_mean_collection = ee.ImageCollection(image_list)\n",
    "\n",
    "# Print the image collection size to confirm\n",
    "print(\"Image collection created with\", monthly_mean_collection.size().getInfo(), \"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4758b81f-76a7-4a6d-aa94-b1b530815d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over images\n",
    "image_collection = monthly_mean_collection\n",
    "\n",
    "# Function to extract data for all grid cells from each image in the ImageCollection\n",
    "def extract_data_for_all_cells(image):\n",
    "    # Use reduceRegions to process all grid cells at once, instead of iterating over them\n",
    "    data = image.reduceRegions(\n",
    "        collection=quarter_degree_grid,\n",
    "        reducer=ee.Reducer.toList(),\n",
    "        scale=27829.87269831839,\n",
    "        crs='EPSG:4326'\n",
    "    )\n",
    "    return data\n",
    "\n",
    "# Iterate over images and extract data for all grid cells at once\n",
    "extracted_data_list = image_collection.map(extract_data_for_all_cells).toList(image_collection.size())\n",
    "\n",
    "# Function to process the extracted data and concatenate arrays for each property\n",
    "def extract_and_concatenate_from_featurecollection(fc):\n",
    "    fc_dict = fc.getInfo()\n",
    "    \n",
    "    features = fc_dict['features']\n",
    "    property_names = features[0]['properties'].keys()\n",
    "\n",
    "    # Create a list of lists to hold property values for each feature\n",
    "    all_property_values = {prop: [] for prop in property_names}\n",
    "\n",
    "    for feature in features:\n",
    "        for prop in property_names:\n",
    "            # Only append values if they are not NaN\n",
    "            if isinstance(feature['properties'][prop], list):\n",
    "                all_property_values[prop].append(feature['properties'][prop])\n",
    "            else:\n",
    "                all_property_values[prop].append([feature['properties'][prop]])\n",
    "\n",
    "    # Now concatenate arrays while ensuring they are of the same length\n",
    "    concatenated_data = {}\n",
    "    for prop in property_names:\n",
    "        # Convert to NumPy array and filter out missing values\n",
    "        valid_data = np.concatenate(all_property_values[prop])\n",
    "        # Filter out NaN values, if any\n",
    "        valid_data = valid_data[~np.isnan(valid_data)]\n",
    "        concatenated_data[prop] = valid_data\n",
    "\n",
    "    return concatenated_data\n",
    "\n",
    "# Initialize a dictionary to hold the final concatenated data across all FeatureCollections, including 'month'\n",
    "final_concatenated_data = {}\n",
    "years_list = []\n",
    "months_list = []\n",
    "\n",
    "# Iterate over each FeatureCollection in the extracted data list\n",
    "for i in range(image_collection.size().getInfo()):\n",
    "    # Get the current image\n",
    "    image = ee.Image(image_collection.toList(image_collection.size()).get(i))\n",
    "    print(f'Extracting image: {i + 1}')\n",
    "\n",
    "    # Extract the 'year' and 'month' properties from the image\n",
    "    year = image.get('year').getInfo()\n",
    "    month = image.get('month').getInfo()\n",
    "    \n",
    "    # Get the current FeatureCollection\n",
    "    fc = ee.FeatureCollection(extracted_data_list.get(i))\n",
    "\n",
    "    # Extract and concatenate the data for this FeatureCollection\n",
    "    concatenated_data = extract_and_concatenate_from_featurecollection(fc)\n",
    "\n",
    "    # Update the final concatenated data and store the 'year' and 'month' value for each image\n",
    "    years_list.append(years)\n",
    "    months_list.append(month)\n",
    "    \n",
    "    for prop, array in concatenated_data.items():\n",
    "        if prop not in final_concatenated_data:\n",
    "            final_concatenated_data[prop] = array\n",
    "        else:\n",
    "            final_concatenated_data[prop] = np.concatenate((final_concatenated_data[prop], array))\n",
    "\n",
    "final_concatenated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b8404a-0bfd-4e96-aa63-dade2625ad13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_array_lengths(data_dict):\n",
    "    array_lengths = {}\n",
    "    \n",
    "    for key, value in data_dict.items():\n",
    "        if hasattr(value, '__len__'):  # Check if the value has a length (e.g., an array)\n",
    "            array_lengths[key] = len(value)\n",
    "    \n",
    "    return array_lengths\n",
    "\n",
    "array_lengths = find_array_lengths(final_concatenated_data)\n",
    "array_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dc960e-7abc-40f9-916c-d3f463159f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the dictionary\n",
    "df = pd.DataFrame.from_dict(final_concatenated_data)\n",
    "df = df[['build_up_index', 'drought_code', 'duff_moisture_code', 'fine_fuel_moisture_code', 'fire_weather_index', 'initial_fire_spread_index', 'latitude', 'longitude']]\n",
    "df.replace(-9999, np.nan, inplace=True)\n",
    "df['month'] = np.repeat(months_list, len(df) // len(months_list))\n",
    "years_flat = [year for sublist in years_list for year in sublist] # Flatten years_list\n",
    "df['year'] = np.repeat(years_flat, len(df) // len(years_flat))\n",
    "df.set_index(['year', 'month'], inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ccab21-d45b-4747-b3ce-f9b1a049fd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export single year to CSV\n",
    "# Specify the CSV file path\n",
    "csv_file_path = 'cems_2014.csv' # <-- Edit as necessary\n",
    "df_reset = df.reset_index()\n",
    "\n",
    "# Export the DataFrame to CSV\n",
    "df_reset.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ea5ada-e52c-40a3-8230-bfd5ddac5be6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Combine all individual years into one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33577934-35ae-4c45-be7c-a385410bb12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all individual years to one Dataframe\n",
    "file_path_pattern = \"/home/users/clelland/Model/NASA_CEMS_comparison/CEMS_annual/cems_*.csv\" # <-- Edit as necessary\n",
    "\n",
    "# Get a list of all the CSV files matching the pattern\n",
    "csv_files = glob.glob(file_path_pattern)\n",
    "\n",
    "# Read and concatenate all the CSV files into one DataFrame\n",
    "combined_df = pd.concat([pd.read_csv(f) for f in csv_files], ignore_index=True)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea85db07-fe8e-4bb6-87a0-817b008bd7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV\n",
    "# Specify the CSV file path\n",
    "csv_file_path = 'cems_0114.csv' # <-- Edit as necessary\n",
    "\n",
    "# Export the DataFrame to CSV\n",
    "combined_df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a119a657-5921-44c3-9bb6-6e24179f8600",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Process ACCESS NASA to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fba5c4-60f0-4dd7-9993-bf6ccd3563ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import downscaled FWI into an image collection\n",
    "# Run and save single years before combining into one master file\n",
    "years = list(range(2014, 2015))  # 2001 to 2014\n",
    "months = list(range(1, 13))  # 1 to 12\n",
    "\n",
    "# Define the new band names\n",
    "band_names = ['BUI', 'DC', 'DMC', 'FFMC', 'FWI', 'FWI_N15', 'FWI_N30', 'FWI_N45', 'FWI_NP95', 'FWI_Nmid', 'ISI']\n",
    "\n",
    "# Google Cloud Storage bucket path template\n",
    "gcs_template = 'gs://clelland_fire_ml/FWI_files/ACCESS-CM2_COG/Historical/ACCESS-CM2_historical_{year}_{month}_cog.tif' # <-- Permission needed: ask Trevor\n",
    "\n",
    "# Function to generate an ee.Image from a GCS path\n",
    "def create_image(year, month):\n",
    "    file_path = gcs_template.format(year=year, month=month)\n",
    "    image = ee.Image.loadGeoTIFF(file_path).clip(final)\n",
    "\n",
    "    # Get the last day of the month\n",
    "    _, last_day = calendar.monthrange(year, month)\n",
    "    \n",
    "    # Define the start and end dates\n",
    "    start_date = f'{year}-{month:02d}-01'\n",
    "    end_date = f'{year}-{month:02d}-{last_day:02d}'\n",
    "\n",
    "    # Rename the bands of the image\n",
    "    image = image.rename(band_names)\n",
    "\n",
    "    # Handle missing pixels for BUI and FWI bands\n",
    "    bui = image.select('BUI')\n",
    "    fwi = image.select('FWI')\n",
    "\n",
    "    # Apply unmask only where pixels are missing\n",
    "    bui_filled = bui.unmask(-9999, sameFootprint=True).updateMask(image.select('FFMC'))\n",
    "    fwi_filled = fwi.unmask(-9999, sameFootprint=True).updateMask(image.select('FFMC'))\n",
    "\n",
    "    # Replace the original BUI and FWI with the filled versions (preserve existing valid pixels)\n",
    "    coords = ee.Image.pixelLonLat().clip(final).updateMask(image.select('FFMC'))\n",
    "    image = image.addBands([bui_filled.rename('BUI'), fwi_filled.rename('FWI')], overwrite=True).addBands(coords)\n",
    "\n",
    "    # Set properties including the start and end dates\n",
    "    image = image.set({\n",
    "        'scenario': 'historical',\n",
    "        'year': year,\n",
    "        'month': month,\n",
    "        'system:time_start': ee.Date(start_date).millis(),\n",
    "        'system:time_end': ee.Date(end_date).millis()\n",
    "    })\n",
    "    return image\n",
    "\n",
    "# Create an empty list to hold the images\n",
    "image_list = []\n",
    "\n",
    "# Loop through scenarios, years, and months, and import the files\n",
    "for year in years:\n",
    "    for month in months:\n",
    "        try:\n",
    "            image = create_image(year, month)\n",
    "            image_list.append(image)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image for {year}-{month}: {e}\")\n",
    "\n",
    "# Convert the list of images to an Earth Engine ImageCollection\n",
    "access_fwi_images = ee.ImageCollection(image_list)\n",
    "\n",
    "# Print the image collection size to confirm\n",
    "print(\"Image collection created with\", access_fwi_images.size().getInfo(), \"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d2a817-0f0b-483e-933e-294c244ed848",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_collection = access_fwi_images\n",
    "\n",
    "# Function to extract data for all grid cells from each image in the ImageCollection\n",
    "def extract_data_for_all_cells(image):\n",
    "    # Use reduceRegions to process all grid cells at once, instead of iterating over them\n",
    "    data = image.reduceRegions(\n",
    "        collection=quarter_degree_grid,\n",
    "        reducer=ee.Reducer.toList(),\n",
    "        scale=27829.87269831839,\n",
    "        crs='EPSG:4326'\n",
    "    )\n",
    "    return data\n",
    "\n",
    "# Iterate over images and extract data for all grid cells at once\n",
    "extracted_data_list = image_collection.map(extract_data_for_all_cells).toList(image_collection.size())\n",
    "\n",
    "# Function to process the extracted data and concatenate arrays for each property\n",
    "def extract_and_concatenate_from_featurecollection(fc):\n",
    "    fc_dict = fc.getInfo()\n",
    "    \n",
    "    features = fc_dict['features']\n",
    "    property_names = features[0]['properties'].keys()\n",
    "\n",
    "    concatenated_data = {prop: [] for prop in property_names}\n",
    "\n",
    "    for feature in features:\n",
    "        for prop in property_names:\n",
    "            concatenated_data[prop].extend(feature['properties'][prop])\n",
    "\n",
    "    # Convert lists to NumPy arrays\n",
    "    for prop in concatenated_data:\n",
    "        concatenated_data[prop] = np.array(concatenated_data[prop])\n",
    "\n",
    "    return concatenated_data\n",
    "\n",
    "# Initialize a dictionary to hold the final concatenated data across all FeatureCollections, including 'month'\n",
    "final_concatenated_data = {}\n",
    "years_list = []\n",
    "months_list = []\n",
    "\n",
    "# Iterate over each FeatureCollection in the extracted data list\n",
    "for i in range(image_collection.size().getInfo()):\n",
    "    # Get the current image\n",
    "    image = ee.Image(image_collection.toList(image_collection.size()).get(i))\n",
    "    print(f'Extracting image: {i + 1}')\n",
    "\n",
    "    # Extract the 'year' and 'month' properties from the image\n",
    "    year = image.get('year').getInfo()\n",
    "    month = image.get('month').getInfo()\n",
    "    \n",
    "    # Get the current FeatureCollection\n",
    "    fc = ee.FeatureCollection(extracted_data_list.get(i))\n",
    "\n",
    "    # Extract and concatenate the data for this FeatureCollection\n",
    "    concatenated_data = extract_and_concatenate_from_featurecollection(fc)\n",
    "\n",
    "    # Update the final concatenated data and store the 'year' and 'month' value for each image\n",
    "    years_list.append(years)\n",
    "    months_list.append(month)\n",
    "    \n",
    "    for prop, array in concatenated_data.items():\n",
    "        if prop not in final_concatenated_data:\n",
    "            final_concatenated_data[prop] = array\n",
    "        else:\n",
    "            final_concatenated_data[prop] = np.concatenate((final_concatenated_data[prop], array))\n",
    "\n",
    "final_concatenated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4157e13-e8e6-41cd-bb43-0231a0379a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_array_lengths(data_dict):\n",
    "    array_lengths = {}\n",
    "    \n",
    "    for key, value in data_dict.items():\n",
    "        if hasattr(value, '__len__'):  # Check if the value has a length (e.g., an array)\n",
    "            array_lengths[key] = len(value)\n",
    "    \n",
    "    return array_lengths\n",
    "\n",
    "array_lengths = find_array_lengths(final_concatenated_data)\n",
    "array_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc1ea14-82c3-44d1-92e0-b6c114f6991d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the dictionary\n",
    "df = pd.DataFrame.from_dict(final_concatenated_data)\n",
    "df = df[['BUI', 'DC', 'DMC', 'FFMC', 'FWI', 'ISI', 'latitude', 'longitude']]\n",
    "df.replace(-9999, np.nan, inplace=True)\n",
    "years_flat = [year for sublist in years_list for year in sublist] # Flatten years_list\n",
    "df['year'] = np.repeat(years_flat, len(df) // len(years_flat))\n",
    "df['month'] = np.repeat(months_list, len(df) // len(months_list))\n",
    "df.set_index(['year', 'month'], inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d887a3b-eb8b-4327-a35f-6dd1f6c3eaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV\n",
    "# Specify the CSV file path\n",
    "csv_file_path = 'access_2014.csv'\n",
    "df_reset = df.reset_index()\n",
    "\n",
    "# Export the DataFrame to CSV\n",
    "df_reset.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d177a07f-c1f9-4b32-b8ca-233ba2c3a023",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Combine all individual years into one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ab5095-af4d-48ac-b47e-7c1c2b4a45b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all individual years to one Dataframe\n",
    "file_path_pattern = \"/home/users/clelland/Model/NASA_CEMS_comparison/ACCESS_annual/access_*.csv\" # <-- Edit as necessary\n",
    "\n",
    "# Get a list of all the CSV files matching the pattern\n",
    "csv_files = glob.glob(file_path_pattern)\n",
    "\n",
    "# Read and concatenate all the CSV files into one DataFrame\n",
    "combined_df = pd.concat([pd.read_csv(f) for f in csv_files], ignore_index=True)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec187c26-9ce9-4f46-9ed8-fcc35733b514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV\n",
    "# Specify the CSV file path\n",
    "csv_file_path = 'access_0114.csv' # <-- Edit as necessary\n",
    "\n",
    "# Export the DataFrame to CSV\n",
    "combined_df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30944c75-2edc-4cda-8e9d-7c695839ece1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Process MRI NASA to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb5c928-9701-46e5-acd3-4254b9f0e697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import downscaled FWI into an image collection\n",
    "# Run and save single years before combining into one master file\n",
    "years = list(range(2014, 2015))  # 2001 to 2014\n",
    "months = list(range(1, 13))  # 1 to 12\n",
    "\n",
    "# Define the new band names\n",
    "band_names = ['BUI', 'DC', 'DMC', 'FFMC', 'FWI', 'FWI_N15', 'FWI_N30', 'FWI_N45', 'FWI_NP95', 'FWI_Nmid', 'ISI']\n",
    "\n",
    "# Google Cloud Storage bucket path template\n",
    "gcs_template = 'gs://clelland_fire_ml/FWI_files/MRI-ESM2-0_COG/Historical/MRI-ESM2-0_historical_{year}_{month}_cog.tif' # Permission required: ask Trevor\n",
    "\n",
    "# Function to generate an ee.Image from a GCS path\n",
    "def create_image(year, month):\n",
    "    file_path = gcs_template.format(year=year, month=month)\n",
    "    image = ee.Image.loadGeoTIFF(file_path).clip(final)\n",
    "\n",
    "    # Get the last day of the month\n",
    "    _, last_day = calendar.monthrange(year, month)\n",
    "    \n",
    "    # Define the start and end dates\n",
    "    start_date = f'{year}-{month:02d}-01'\n",
    "    end_date = f'{year}-{month:02d}-{last_day:02d}'\n",
    "\n",
    "    # Rename the bands of the image\n",
    "    image = image.rename(band_names)\n",
    "\n",
    "    # Handle missing pixels for BUI and FWI bands\n",
    "    bui = image.select('BUI')\n",
    "    fwi = image.select('FWI')\n",
    "\n",
    "    # Apply unmask only where pixels are missing\n",
    "    bui_filled = bui.unmask(-9999, sameFootprint=True).updateMask(image.select('FFMC'))\n",
    "    fwi_filled = fwi.unmask(-9999, sameFootprint=True).updateMask(image.select('FFMC'))\n",
    "\n",
    "    # Replace the original BUI and FWI with the filled versions (preserve existing valid pixels)\n",
    "    coords = ee.Image.pixelLonLat().clip(final).updateMask(image.select('FFMC'))\n",
    "    image = image.addBands([bui_filled.rename('BUI'), fwi_filled.rename('FWI')], overwrite=True).addBands(coords)\n",
    "\n",
    "    # Set properties including the start and end dates\n",
    "    image = image.set({\n",
    "        'scenario': 'historical',\n",
    "        'year': year,\n",
    "        'month': month,\n",
    "        'system:time_start': ee.Date(start_date).millis(),\n",
    "        'system:time_end': ee.Date(end_date).millis()\n",
    "    })\n",
    "    return image\n",
    "\n",
    "# Create an empty list to hold the images\n",
    "image_list = []\n",
    "\n",
    "# Loop through scenarios, years, and months, and import the files\n",
    "for year in years:\n",
    "    for month in months:\n",
    "        try:\n",
    "            image = create_image(year, month)\n",
    "            image_list.append(image)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image for {year}-{month}: {e}\")\n",
    "\n",
    "# Convert the list of images to an Earth Engine ImageCollection\n",
    "mri_fwi_images = ee.ImageCollection(image_list)\n",
    "\n",
    "# Print the image collection size to confirm\n",
    "print(\"Image collection created with\", mri_fwi_images.size().getInfo(), \"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aae68bd-afff-4cff-bf2d-f38fa6127de0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_collection = mri_fwi_images\n",
    "\n",
    "# Function to extract data for all grid cells from each image in the ImageCollection\n",
    "def extract_data_for_all_cells(image):\n",
    "    # Use reduceRegions to process all grid cells at once, instead of iterating over them\n",
    "    data = image.reduceRegions(\n",
    "        collection=quarter_degree_grid,\n",
    "        reducer=ee.Reducer.toList(),\n",
    "        scale=27829.87269831839,\n",
    "        crs='EPSG:4326'\n",
    "    )\n",
    "    return data\n",
    "\n",
    "# Iterate over images and extract data for all grid cells at once\n",
    "extracted_data_list = image_collection.map(extract_data_for_all_cells).toList(image_collection.size())\n",
    "\n",
    "# Function to process the extracted data and concatenate arrays for each property\n",
    "def extract_and_concatenate_from_featurecollection(fc):\n",
    "    fc_dict = fc.getInfo()\n",
    "    \n",
    "    features = fc_dict['features']\n",
    "    property_names = features[0]['properties'].keys()\n",
    "\n",
    "    concatenated_data = {prop: [] for prop in property_names}\n",
    "\n",
    "    for feature in features:\n",
    "        for prop in property_names:\n",
    "            concatenated_data[prop].extend(feature['properties'][prop])\n",
    "\n",
    "    # Convert lists to NumPy arrays\n",
    "    for prop in concatenated_data:\n",
    "        concatenated_data[prop] = np.array(concatenated_data[prop])\n",
    "\n",
    "    return concatenated_data\n",
    "\n",
    "# Initialize a dictionary to hold the final concatenated data across all FeatureCollections, including 'month'\n",
    "final_concatenated_data = {}\n",
    "years_list = []\n",
    "months_list = []\n",
    "\n",
    "# Iterate over each FeatureCollection in the extracted data list\n",
    "for i in range(image_collection.size().getInfo()):\n",
    "    # Get the current image\n",
    "    image = ee.Image(image_collection.toList(image_collection.size()).get(i))\n",
    "    print(f'Extracting image: {i + 1}')\n",
    "    \n",
    "    # Extract the 'year' and 'month' properties from the image\n",
    "    year = image.get('year').getInfo()\n",
    "    month = image.get('month').getInfo()\n",
    "    \n",
    "    # Get the current FeatureCollection\n",
    "    fc = ee.FeatureCollection(extracted_data_list.get(i))\n",
    "\n",
    "    # Extract and concatenate the data for this FeatureCollection\n",
    "    concatenated_data = extract_and_concatenate_from_featurecollection(fc)\n",
    "\n",
    "    # Update the final concatenated data and store the 'year' and 'month' value for each image\n",
    "    years_list.append(years)\n",
    "    months_list.append(month)\n",
    "    \n",
    "    for prop, array in concatenated_data.items():\n",
    "        if prop not in final_concatenated_data:\n",
    "            final_concatenated_data[prop] = array\n",
    "        else:\n",
    "            final_concatenated_data[prop] = np.concatenate((final_concatenated_data[prop], array))\n",
    "\n",
    "final_concatenated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8bc52c-7bc2-43c6-bf0e-ccd8b7e55c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_array_lengths(data_dict):\n",
    "    array_lengths = {}\n",
    "    \n",
    "    for key, value in data_dict.items():\n",
    "        if hasattr(value, '__len__'):  # Check if the value has a length (e.g., an array)\n",
    "            array_lengths[key] = len(value)\n",
    "    \n",
    "    return array_lengths\n",
    "\n",
    "array_lengths = find_array_lengths(final_concatenated_data)\n",
    "array_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd63e75-07ac-4604-84d1-13e149e9f9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the dictionary\n",
    "df = pd.DataFrame.from_dict(final_concatenated_data)\n",
    "df = df[['BUI', 'DC', 'DMC', 'FFMC', 'FWI', 'ISI', 'latitude', 'longitude']]\n",
    "df.replace(-9999, np.nan, inplace=True)\n",
    "years_flat = [year for sublist in years_list for year in sublist] # Flatten years_list\n",
    "df['year'] = np.repeat(years_flat, len(df) // len(years_flat))\n",
    "df['month'] = np.repeat(months_list, len(df) // len(months_list))\n",
    "df.set_index(['year', 'month'], inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152f2620-9f3c-4732-a06a-45c18ac65aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV\n",
    "# Specify the CSV file path\n",
    "csv_file_path = 'mri_2014.csv' # <-- Edit as necessary\n",
    "df_reset = df.reset_index()\n",
    "\n",
    "# Export the DataFrame to CSV\n",
    "df_reset.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473a7d3f-83b3-4c2e-9e75-c8eaa347c469",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Combine all individual years into one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea08482-2efb-4cc9-ae2b-b9e4831ae71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all individual years to one Dataframe\n",
    "file_path_pattern = \"/home/users/clelland/Model/NASA_CEMS_comparison/MRI_annual/mri_*.csv\" # <-- Edit as necessary\n",
    "\n",
    "# Get a list of all the CSV files matching the pattern\n",
    "csv_files = glob.glob(file_path_pattern)\n",
    "\n",
    "# Read and concatenate all the CSV files into one DataFrame\n",
    "combined_df = pd.concat([pd.read_csv(f) for f in csv_files], ignore_index=True)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3cb133-f9d4-409e-acd9-c65c36f519ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV\n",
    "# Specify the CSV file path\n",
    "csv_file_path = 'mri_0114.csv' # <-- Edit as necessary\n",
    "\n",
    "# Export the DataFrame to CSV\n",
    "combined_df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13886e8-5397-4d39-9f3e-b011dc7b3aac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
